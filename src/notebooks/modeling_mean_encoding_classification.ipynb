{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "In this file, instructions how to approach the challenge can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cfsui\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>crs_dep_time</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>taxi_out</th>\n",
       "      <th>...</th>\n",
       "      <th>arr_hr_sin</th>\n",
       "      <th>arr_hr_cos</th>\n",
       "      <th>fl_mnth_sin</th>\n",
       "      <th>fl_mnth_cos</th>\n",
       "      <th>fl_wkday_sin</th>\n",
       "      <th>fl_wkday_cos</th>\n",
       "      <th>day_num_of_flights</th>\n",
       "      <th>num_flights_6hrs</th>\n",
       "      <th>inbound_fl_num</th>\n",
       "      <th>inbound_fl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>PT</td>\n",
       "      <td>N645AE</td>\n",
       "      <td>4857</td>\n",
       "      <td>14100</td>\n",
       "      <td>11577</td>\n",
       "      <td>1900-01-01 21:30:00</td>\n",
       "      <td>2129.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>UA</td>\n",
       "      <td>N817UA</td>\n",
       "      <td>1249</td>\n",
       "      <td>12953</td>\n",
       "      <td>13930</td>\n",
       "      <td>1900-01-01 21:00:00</td>\n",
       "      <td>2058.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>AX</td>\n",
       "      <td>N14116</td>\n",
       "      <td>4650</td>\n",
       "      <td>11292</td>\n",
       "      <td>14783</td>\n",
       "      <td>1900-01-01 12:30:00</td>\n",
       "      <td>1237.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.433884</td>\n",
       "      <td>-0.900969</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fl_date op_unique_carrier tail_num  op_carrier_fl_num  \\\n",
       "0  2019-04-08                PT   N645AE               4857   \n",
       "1  2018-11-29                UA   N817UA               1249   \n",
       "2  2018-08-03                AX   N14116               4650   \n",
       "\n",
       "   origin_airport_id  dest_airport_id         crs_dep_time  dep_time  \\\n",
       "0              14100            11577  1900-01-01 21:30:00    2129.0   \n",
       "1              12953            13930  1900-01-01 21:00:00    2058.0   \n",
       "2              11292            14783  1900-01-01 12:30:00    1237.0   \n",
       "\n",
       "   dep_delay  taxi_out  ...  arr_hr_sin  arr_hr_cos  fl_mnth_sin fl_mnth_cos  \\\n",
       "0       -1.0      37.0  ...   -0.500000    0.866025     0.866025   -0.500000   \n",
       "1       -2.0      25.0  ...   -0.500000    0.866025    -0.500000    0.866025   \n",
       "2        7.0      13.0  ...   -0.707107   -0.707107    -0.866025   -0.500000   \n",
       "\n",
       "   fl_wkday_sin  fl_wkday_cos  day_num_of_flights num_flights_6hrs  \\\n",
       "0      0.000000      1.000000                  10                6   \n",
       "1      0.433884     -0.900969                   1                1   \n",
       "2     -0.433884     -0.900969                   5               11   \n",
       "\n",
       "   inbound_fl_num  inbound_fl  \n",
       "0               0           0  \n",
       "1               0           0  \n",
       "2               0           0  \n",
       "\n",
       "[3 rows x 62 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"data/flights_preprocessed_37k.csv\", index_col=0)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['arr_delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.label <= 0, 'label'] = 0\n",
    "df.loc[(df.label > 0) & (df.label <= 15), 'label'] = 1\n",
    "df.loc[(df.label > 15) & (df.label <= 180), 'label'] = 2\n",
    "df.loc[df.label > 180, 'label'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transform some new features by using 'arr_delay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split traing and test set first\n",
    "# In training set, I'm going to add more feature generated by combining 'arr_delay' and some categorial features\n",
    "# For test set, same features as above mentioned should be added with values computed from training set\n",
    "# i.e. DON NOT touch target variable in test set from now on\n",
    "df_train, df_test = train_test_split(df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate how many times has delay ('arr_delay' > 15) happened on each carrier/flight_num/tail_num/carrier/origin_airport/dest_airport/origin_city/origin_state/dest_city/dest_state \n",
    "# calculate average/median delay time of each ... (same as above)\n",
    "# merge with df\n",
    "\n",
    "tran_features = ['op_unique_carrier', 'tail_num',  'op_carrier_fl_num', 'origin_airport_id', 'dest_airport_id', 'origin_city', 'origin_state', 'dest_city', 'dest_state']\n",
    "\n",
    "for col in tran_features:\n",
    "    # delay count group by col\n",
    "    feature_delay_ct = df_train[df_train['arr_delay'] > 15][[col, 'arr_delay']].groupby(col, as_index=False).count().rename(columns={'arr_delay': f'{col}_delayct'})\n",
    "    df_train = pd.merge(df_train, feature_delay_ct, on=col, how='left').fillna(0)\n",
    "    # average delay time group by col\n",
    "    feature_delay_avg = df[[col, 'arr_delay']].groupby(col, as_index=False).mean().rename(columns={'arr_delay': f'{col}_delayavg'})\n",
    "    df_train = pd.merge(df_train, feature_delay_avg, on=col, how='left').fillna(0)\n",
    "    # median delay time group by col\n",
    "    feature_delay_median = df[[col, 'arr_delay']].groupby(col, as_index=False).median().rename(columns={'arr_delay': f'{col}_delaymedian'})\n",
    "    df_train = pd.merge(df_train, feature_delay_median, on=col, how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset dtypes\n",
    "categorical_features = ['op_unique_carrier',\n",
    "                        'tail_num', \n",
    "                        'op_carrier_fl_num',\n",
    "                        'origin_airport_id',\n",
    "                        'dest_airport_id',\n",
    "                        # 'share_code',\n",
    "                        'origin_city',\n",
    "                        'origin_state',\n",
    "                        'dest_city',\n",
    "                        'dest_state',\n",
    "                        'fl_month',\n",
    "                        'fl_weekday',\n",
    "                        'season',\n",
    "                        'inbound_fl']\n",
    "\n",
    "df_train[categorical_features] = df_train[categorical_features].astype('str')\n",
    "df_test[categorical_features] =df_test[categorical_features].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11232, 63)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add features to test set with values computed by training set\n",
    "# NOTICE: THE VALUES ADDED HERE ARE STILL FROM TRAINING SET\n",
    "# for example, flight No.#### used to have 7 delays in training set, then add 7 to same flight No. in test set\n",
    "# It's like assigning weight to categories (assign weight of 7 to flight No.##### in this example)\n",
    "\n",
    "origin_new = [['op_unique_carrier', 'op_unique_carrier_delayct', 'op_unique_carrier_delaymedian', 'op_unique_carrier_delayavg'],\n",
    "              ['tail_num', 'tail_num_delayct', 'tail_num_delaymedian', 'tail_num_delayavg'],\n",
    "              ['op_carrier_fl_num', 'op_carrier_fl_num_delayct', 'op_carrier_fl_num_delaymedian', 'op_carrier_fl_num_delayavg'],\n",
    "              ['origin_airport_id', 'origin_airport_id_delayct', 'origin_airport_id_delaymedian', 'origin_airport_id_delayavg'],\n",
    "              ['dest_airport_id', 'dest_airport_id_delayct', 'dest_airport_id_delaymedian', 'dest_airport_id_delayavg'],\n",
    "              ['origin_city', 'origin_city_delayct', 'origin_city_delaymedian', 'origin_city_delayavg'],\n",
    "              ['origin_state', 'origin_state_delayct', 'origin_state_delaymedian', 'origin_state_delayavg'],\n",
    "              ['dest_city', 'dest_city_delayct', 'dest_city_delaymedian', 'dest_city_delayavg'],\n",
    "              ['dest_state', 'dest_state_delayct', 'dest_state_delaymedian', 'dest_state_delayavg']]\n",
    "              \n",
    "for cols in origin_new:\n",
    "    df_test = pd.merge(df_test, df_train[cols].drop_duplicates(), on=cols[0], how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11232, 90)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main Task: Classification Problem\n",
    "Convert delay time into 4 classes: \n",
    "- 0: on-time (<=0)\n",
    "- 1: mild delay (0,15]\n",
    "- 2: moderate delay (15,180]\n",
    "- 3: severe delay (>180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_features = [\n",
    "    # 'fl_date',\n",
    "    # 'op_unique_carrier',\n",
    "    # 'tail_num', \n",
    "    # 'op_carrier_fl_num',\n",
    "    # 'origin_airport_id',\n",
    "    # 'dest_airport_id',\n",
    "    # 'crs_dep_time',\n",
    "    # 'crs_arr_time',\n",
    "    # 'crs_elapsed_time',\n",
    "    'distance',\n",
    "    # 'share_code',\n",
    "    # 'origin_city',\n",
    "    # 'origin_state',\n",
    "    # 'dest_city',\n",
    "    # 'dest_state',\n",
    "    # 'arr_date',\n",
    "    # 'dep_datetime',\n",
    "    # 'arr_datetime',\n",
    "    # 'fl_month',\n",
    "    # 'fl_weekday',\n",
    "    # 'season',\n",
    "    # 'day_num_of_flights',\n",
    "    'num_flights_6hrs',\n",
    "    'inbound_fl_num',\n",
    "    # 'inbound_fl',\n",
    "    # 'dep_min_of_day',\n",
    "    # 'arr_min_of_day',\n",
    "    # 'dep_hr',\n",
    "    # 'arr_hr',\n",
    "    'arr_min_sin',\n",
    "    'arr_min_cos',\n",
    "    # 'arr_hr_sin',\n",
    "    # 'arr_hr_cos',\n",
    "    'dep_min_sin', \n",
    "    'dep_min_cos', \n",
    "    # 'dep_hr_sin', \n",
    "    # 'dep_hr_cos',\n",
    "    'fl_mnth_sin', \n",
    "    'fl_mnth_cos',\n",
    "    'fl_wkday_sin',\n",
    "    'fl_wkday_cos',\n",
    "    'op_unique_carrier_delayct',\n",
    "    'op_unique_carrier_delaymedian',\n",
    "    # 'op_unique_carrier_delayavg',\n",
    "    # 'tail_num_delayct', \n",
    "    # 'tail_num_delaymedian',\n",
    "    'tail_num_delayavg',\n",
    "    # 'op_carrier_fl_num_delayct',\n",
    "    # 'op_carrier_fl_num_delaymedian', \n",
    "    'op_carrier_fl_num_delayavg',\n",
    "    'origin_airport_id_delayct', \n",
    "    # 'origin_airport_id_delaymedian',\n",
    "    'origin_airport_id_delayavg',\n",
    "    'dest_airport_id_delayct',\n",
    "    # 'dest_airport_id_delaymedian',\n",
    "    'dest_airport_id_delayavg',\n",
    "    'origin_city_delayct',\n",
    "    'origin_city_delaymedian', \n",
    "    # 'origin_city_delayavg',\n",
    "    'origin_state_delayct', \n",
    "    'origin_state_delaymedian',\n",
    "    # 'origin_state_delayavg',\n",
    "    'dest_city_delayct', \n",
    "    'dest_city_delaymedian',\n",
    "    # 'dest_city_delayavg',\n",
    "    # 'dest_state_delayct',\n",
    "    # 'dest_state_delaymedian',\n",
    "    'dest_state_delayavg'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[avail_features]\n",
    "y_train = df_train.label\n",
    "X_test = df_test[avail_features]\n",
    "y_test = df_test.label\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cfsui\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:19:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf = XGBClassifier()\n",
    "xg_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6674679487179487"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6696047008547008"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
